apiVersion: "sparkoperator.k8s.io/v1beta2"
kind: SparkApplication
metadata:
  name: nyc-taxi-vendor-count
  namespace: spark
spec:
  type: Python
  mode: cluster
  image: public.ecr.aws/data-on-eks/spark:3.5.3-scala2.12-java17-python3-ubuntu
  mainApplicationFile: "s3a://$(BUCKET_PARAM)/app_code/job/NYCTaxiCount.py"
  arguments: ["s3a://$(BUCKET_PARAM)/data/*.parquet"]
  sparkVersion: "3.5.3"
  sparkConf:
    "spark.hadoop.fs.s3a.impl": "org.apache.hadoop.fs.s3a.S3AFileSystem"
    "spark.hadoop.fs.s3a.aws.credentials.provider": "software.amazon.awssdk.auth.credentials.WebIdentityTokenFileCredentialsProvider"
    "spark.kubernetes.driver.label.lifecycle": "OnDemand"
  dynamicAllocation:
    enabled: true
    maxExecutors: 20
  driver:
    env:
      - name: BUCKET_PARAM
        valueFrom:
          configMapKeyRef:
            name: special-config
            key: appcodeBucket
    cores: 1
    memory: "1G"
    labels:
      role: driver
    serviceAccount: nativejob
  executor:
    cores: 1
    memory: "8G"
    labels:
      role: executor